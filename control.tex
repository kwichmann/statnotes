\documentclass[12pt, a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{mathtools}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\numberwithin{equation}{section}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\graphicspath{ {img/} }
\DeclareGraphicsExtensions{.png, .jpg}

\title{Control Theory}
\author{Kristian Wichmann}

\begin{document}
\maketitle

\section{Control and error}
\emph{Control theory} deals with strategies for keeping a quantity at a constant level in a dynamic system. In mathematical terms we try to keep a quantity $y(t)$ at a constant level $y_r$ over time $t$.

To achieve this goal, a \emph{controller} will affect the system at all time. This will generally be based on the \emph{error}, i.e. the deviation from the desired level:
\begin{equation}
e(t)=y_r-y(t)
\end{equation}

\section{P-control}
\emph{P-control} is the case where the controller correction $u$ is proportional (hence the P) to the error:
\begin{equation}
u(t)=ke(t)=k(y_r-y(t))
\end{equation}

\subsection{Example: Anaesthesia}
Surgery is performed on a patient. During the procedure, it is desirable to keep the blood concentration of anaesthetic $y(t)$ at a constant level $y_r$. Without control, the concentration follows the following differential equation:
\begin{equation}
\frac{dy}{dt}=-ay
\end{equation}
I.e. it will decay exponentially from a starting concentration $y_0=y(0)$:
\begin{equation}
y(t)=y_0\cdot e^{-at}
\end{equation}
We now add the control term:
\begin{equation}
\frac{dy}{dt}=-ay+u=-ay+k(y_r-y(t))=ky_r-(a+k)y
\end{equation}
This is a differential equation of the form:
\begin{equation}
\frac{dy}{dy}=b+ay
\end{equation}
Which has the general solution:
\begin{equation}
y(t)=-\frac{b}{a}+c\cdot e^{at}
\end{equation}
Here, this means:
\begin{equation}
y(t)=\frac{ky_r}{a+k}+c\cdot e^{-(a+k)t}
\end{equation}
With the boundary condition that $y(0)=0$ we can determine $c$:
\begin{equation}
c=-\frac{ky_r}{a+k}
\end{equation}
We can now write the solution as:
\begin{equation}
y(t)=\frac{ky_r}{a+k}-\frac{ky_r}{a+k}e^{-(a+k)t}
\end{equation}
So the error is:
\begin{equation}
e(t)=y_r-y(t)=y_r-\frac{ky_r}{a+k}+\frac{ky_r}{a+k}e^{-(a+k)t}
\end{equation}
Expand first term to get common denominator:
\begin{align}
e(t)&=\frac{y_r(a+k)}{a+k}-\frac{ky_r}{a+k}+\frac{ky_r}{a+k}e^{-(a+k)t}\\
&=\frac{y_ra}{a+k}+\frac{y_rk}{a+k}e^{-(a+k)t}\label{anaes_error}
\end{align}
The controller dose is then found by multiplying by $k$:
\begin{equation}
u(t)=\frac{y_rak}{a+k}+\frac{y_rk^2}{a+k}e^{-(a+k)t}
\end{equation}
However, we now see that in the limit $t\rightarrow\infty$ the error is actually not zero, as we would hope for, but instead:
\begin{equation}
\lim_{t\rightarrow\infty}e(t)=y_r\frac{a}{a+k}
\end{equation}

\section{Laplace transforms}
Given a function $f=f(t)$ defined for all positive $t$. Then the Laplace transform of it is defined as:
\begin{equation}
\mathcal{L}[f](s)=\int_0^\infty f(t)e^{-ts}\ dt
\end{equation}
The notation $F(s)$ is often used as a shorthand, and similarly for other functions.

\subsection{Properties of the Laplace transform}
The Laplace transform is linear, since integration is:
\begin{align}
\mathcal{L}[af+bg](s)&=\int_0^\infty\left[af(t)+b(g(t)\right]e^{-ts}\ dt\\
&=a\int_0^\infty f(t)e^{-ts}\ dt+b\int_0^\infty g(t)e^{-ts}\ dt\\
&=a\mathcal{L}[f](s)+b\mathcal{L}[g](s)
\end{align}
Laplace transforming a derivative gives us:
\begin{align}
\mathcal{L}\left[\frac{df}{dt}\right](s)&=\int_0^\infty \frac{df(t)}{dt}e^{-ts}\ dt\\
&=\left[f(t)e^{-ts}\right]_0^\infty-\int_0^\infty f(t)\frac{d}{dt}e^{-ts}\ dt\\
&=-f(0)+s\int_0^\infty f(t)e^{-ts}\ dt\\
&=s\mathcal{L}[f](s)-f(0)
\end{align}
Here partial integration has been used. Note that we have assumed that $f(t)$ grows slower than an exponential for $t\rightarrow\infty$.

Similarly, we can transform an integral:
\begin{align}
\mathcal{L}\left[\int_0^t f(x)\ dx\right](s)&=\int_0^\infty\int_0^t f(x)\ dx\ e^{-ts}\ dt\\
&=\left[\int_0^t f(x)\ dx\cdot\left(-\frac{1}{s}\right)e^{-ts}\right]_0^\infty-\int_0^\infty f(t)\left(-\frac{1}{s}\right)e^{-ts}\ dt\\
&=\frac{1}{s}\mathcal{L}[f](s)
\end{align}
Again, we have made assumptions on the growth speed of the integrand, i.e. this time of the integral of $f$.

\subsection{A few select Laplace transforms}
We consider three specific Laplace transforms in this section. First of a constant:
\begin{align}
\mathcal{L}[k](s)&=\int_0^\infty k\cdot e^{-st}\ dt\\
&=k\int_0^\infty e^{-st}\ dt\\
&=-\frac{k}{s}[e^{-st}]_0^\infty=\frac{k}{s}
\end{align}
Then of an exponential:
\begin{align}
\mathcal{L}[k](e^{at})&=\int_0^\infty e^{at}\cdot e^{-st}\ dt\\
&=\int_0^\infty e^{(a-s)t}\ dt\\
&=\left[\frac{1}{a-s}e^{(a-s)t}\right]_0^\infty=\frac{1}{s-a}
\end{align}
And finally of the function $te^{at}$:
\begin{align}
\mathcal{L}[te^{at}](s)&=\int_0^\infty te^{at}\cdot e^{-st}\ dt\\
&=\int_0^\infty te^{(a-s)t}\ dt\\
&=\left[t\frac{1}{a-s}e^{(a-s)t}\right]_0^\infty-\int_0^\infty 1\cdot\frac{1}{a-s}e^{(a-s)t}\ dt=\frac{1}{(s-a)^2}
\end{align}

\subsection{Anaesthesia revisited}
Consider now the example from the previous section. Here, there's three equations governing the behaviour of the system:
\begin{align}
e(t)&=y_r-y(t)\\
u(t)&=k\cdot e(t)\\
\frac{d}{dt}y(t)&=a\cdot y(t)+u(t)
\end{align}
Now Laplace transform all three equations, using the properties derived above:
\begin{align}
E(s)&=\frac{y_r}{s}-Y(s)\label{anaesE}\\
U(s)&=k E(s)\label{aneasU}\\
s Y(s)-y(0)&=-a Y(s)+U(s)\label{aneasY}
\end{align}
Again, we use the boundary condition $y(0)=0$ to simplify. We wish to isolate $E(t)$. First isolate $Y(t)$ in \ref{aneasY}:
\begin{equation}
(s+a)Y(s)=U(s)\Leftrightarrow Y(s)=\frac{U(s)}{s+a}
\end{equation}
Combined with \ref{aneasU} this gives:
\begin{equation}
Y(s)=\frac{k E(s)}{s+a}
\end{equation}
And finally inserting into \ref{anaesE}:
\begin{align}
E(s)&=\frac{y_r}{s}-\frac{k E(s)}{s+a}\Leftrightarrow\\
(s+a)E(s)&=\frac{y_r(s+a)}{s}-k E(s)\Leftrightarrow\\
(s+a+k)E(s)&=\frac{y_r(s+a)}{s}\Leftrightarrow\\
E(s)&=\frac{y_r(s+a)}{s(s+a+k)}
\end{align}
We now use a partial fraction expansion on the right side:
\begin{equation}
\frac{y_r(s+a)}{s(s+a+k)}=y_r\left(\frac{A_1}{s}+\frac{A_2}{s+a+k}\right)
\end{equation}
For this to hold, we must have:
\begin{equation}
\frac{s+a}{s(s+a+k)}=\frac{(s+a+k)A_1}{s(s+a+k)}+\frac{s A_2}{s(s+a+k)}
\end{equation}
So:
\begin{equation}
s+a=(s+a+k)A_1+sA_2=s(A_1+A_2)+(a+k)A_1
\end{equation}
This is one equation with two unknowns, so we can set a boundary condition ourselves. Setting $A_1+A_2=1$ simplifies this $s$ part. It also means that $A_1=1-A_2$:
\begin{align}
s+a&=s+(a+k)(1-A_2)\Leftrightarrow\\
a&=(a+k)(1-A_2)\Leftrightarrow\\
A_2&=1-\frac{a}{a+k}=\frac{k}{a+k}
\end{align}
Similarly:
\begin{equation}
A_1=1-A_2=1-\frac{k}{a+k}=\frac{a}{a+k}
\end{equation}
Putting it all together the error can be written:
\begin{equation}
E(s)=y_r\frac{a}{a+k}\underbrace{\frac{1}{s}}_{\mathcal{L}[1]}+y_r\frac{k}{a+k}\underbrace{\frac{1}{s+a+k}}_{\mathcal{L}[e^{-(a+k)t}]}
\end{equation}
As the braces show, we recognize two of the Laplace transforms from the previous section. Therefore, we find the original error $e(t)$ to be:
\begin{equation}
e(t)=y_r\frac{a}{a+k}+y_r\frac{k}{a+k}e^{-(a+k)t}
\end{equation}
This is the same as the result from \ref{anaes_error}.

This may seem like a way more complicated way to get the same result as solving a standard differential equation. But is shows how Laplace transforms can be useful to solve problems like this.

\section{PI-control}
\emph{PI-control} is an extension of P-control, which also includes a term proportional to the integral of the error function. Hence the I is short for integration. In mathematical terms:
\begin{equation}
u(t)=k_1e(t)+k_2\int_0^t e(t')\ dt'
\end{equation}
Otherwise, the problem stays the same, so the three Laplace transformed equations become:
\begin{align}
E(s)&=\frac{y_r}{s}-Y(s)\label{PI-E}\\
U(s)&=k_1 E(s)+k_2\frac{E(s)}{s}\label{PI-U}\\
s Y(s)&=-a Y(s)+U(s)\label{PI-Y}
\end{align}
Here the transformation rule for an integral has come in handy, and we have once again assumed $y(0)=0$. Once again, \ref{PI-Y} can be written:
\begin{equation}
U(s)=(s+a)Y(s)
\end{equation}
Insert this in \ref{PI-U}:
\begin{equation}
(s+a)Y(s)=\left[k_1+\frac{k_2}{s}\right]E(s)\label{PI-step}
\end{equation}
From \ref{PI-E} we get:
\begin{equation}
Y(s)=\frac{y_r}{s}-E(s)
\end{equation}
Insert in \ref{PI-step}:
\begin{align}
(s+a)\left[\frac{y_r}{s}-E(s)\right]&=\left[k_1+\frac{k_2}{s}\right]E(s)\Leftrightarrow\\
(s+a)\frac{y_r}{s}-(s+a)E(s)&=\left[k_1+\frac{k_2}{s}\right]E(s)\Leftrightarrow\\
(s+a)\frac{y_r}{s}&=\left[k_1+\frac{k_2}{s}+s+a\right]E(s)
\end{align}
Now isolate $E(s)$ to get:
\begin{equation}
E(s)=\frac{s+a}{k_1+\frac{k_2}{s}+s+a}\frac{y_r}{s}=\frac{s+a}{s^2+(k_1+a)s+k_2}y_r\label{PI_error}
\end{equation}

\subsection{Rewriting the error}
To rewrite the error consider an expression of the more general form:
\begin{equation}
\frac{s+a}{s^2+bs+c}
\end{equation}

\begin{theorem}
\label{rewrite_error_theorem}
If the polynomial $p(s)=s^2+bs+c$ has two distinct roots $\omega_1$ and $\omega_2$, then:
\begin{equation}
\frac{s+a}{s^2+bs+c}=\frac{a+\omega_1}{\omega_2-\omega_1}\frac{1}{s-\omega_1}+\frac{a+\omega_2}{\omega_1-\omega_2}\frac{1}{s-\omega_2}
\end{equation}
If the polynomial has a double root $\omega$, then:
\begin{equation}
\frac{s+a}{s^2+bs+c}=\frac{1}{s-\omega}+\frac{a+\omega}{(s-\omega)^2}
\end{equation}
\end{theorem}

\begin{proof}
For distict roots: The polynomial can be factored as:
\begin{equation}
p(s)=(s-\omega_1)(s-\omega_2)
\end{equation}
We now do a partial fraction expansion:
\begin{equation}
\frac{s+a}{(s-\omega_1)(s-\omega_2)}=\frac{A_1}{s-\omega_1}+\frac{A_2}{s-\omega_2}=\frac{A_1(s-\omega_2)+A_2(s-\omega_1)}{(s-\omega_1)(s-\omega_2)}
\end{equation}
So:
\begin{equation}
s+a=A_1(s-\omega_2)+A_2(s-\omega_1)=(A_1+A_2)s-A_1\omega_2-\omega_1 A_2
\end{equation}
Choose $A_1+A_2=1$. This means $A_2=1-A_1$:
\begin{align}
s+a&=s-A_1\omega_2-\omega_1(1-A_1)\Leftrightarrow\\
a&=-A_1\omega_2-\omega_1+A_1\omega_1\Leftrightarrow\\
a&=(\omega_1-\omega_2)A_1-\omega_1\Leftrightarrow\\
A_1&=\frac{a+\omega_1}{\omega_1-\omega_2}
\end{align}
Now $A_2$ can be found:
\begin{align}
A_2&=1-\frac{a+\omega_1}{\omega_1-\omega_2}\\
&=1+\frac{a+\omega_1}{\omega_2-\omega_1}\\
&=\frac{\omega_2-\omega_1+a+\omega_1}{\omega_2-\omega_1}\\
&=\frac{a+\omega_2}{\omega_2-\omega_1}
\end{align}
This proves the distinct case.

When there's a double root, the factorization is:
\begin{equation}
p(s)=(s-\omega)^2
\end{equation}
Reduce the proposed rewrite of the fraction:
\begin{equation}
\frac{1}{s-\omega}+\frac{a+\omega}{(s-\omega)^2}=\frac{s-\omega+a+\omega}{(s-\omega)^2}=\frac{s+a}{(s-\omega)^2}
\end{equation}
The denominator is now equal to $p(s)$, and we're done.
\end{proof}

\subsection{Solving the PI-control equations}
Wanting to apply theorem \ref{rewrite_error_theorem} to \ref{PI_error} we look for roots of the denominator. The discriminant is:
\begin{equation}
d=(k_1+a)^2-4k_2
\end{equation}
So when $(k_1+a)^2>4k_2$ there's two distinct roots, found by the usual formula:
\begin{equation}
\omega_1=\frac{-(k_1+a)+\sqrt{d}}{2},\quad\omega_2=\frac{-(k_1+a)-\sqrt{d}}{2}
\end{equation}
We now get the error function:
\begin{equation}
E(s)=\frac{a+\omega_1}{\omega_2-\omega_1}\underbrace{\frac{1}{s-\omega_1}}_{\mathcal{L}[e^{\omega_1t}]}+\frac{a+\omega_2}{\omega_1-\omega_2}\underbrace{\frac{1}{s-\omega_2}}_{\mathcal{L}[e^{\omega_2t}]}
\end{equation}
As shown by the braces, in this case the solution in the time domain is:
\begin{equation}
e(t)=\frac{a+\omega_1}{\omega_2-\omega_1}e^{\omega_1t}+\frac{a+\omega_2}{\omega_1-\omega_2}e^{\omega_2t}
\end{equation}
If $(k_1+a)^2=4k_2$ there's a double root:
\begin{equation}
\omega=-\frac{k_1+a}{2}
\end{equation}
In this case the error function is:
\begin{equation}
E(s)=\underbrace{\frac{1}{s-\omega}}_{\mathcal{L}[e^{\omega t}]}+(a+\omega)\underbrace{\frac{1}{(s-\omega)^2}}_{\mathcal{L}[te^{\omega t}]}
\end{equation}
So in the time domain:
\begin{equation}
e(t)=e^{\omega t}+(a+\omega)te^{\omega t}
\end{equation}

\end{document}
