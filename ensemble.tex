\documentclass[12pt, a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{mathtools}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\numberwithin{equation}{section}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\graphicspath{ {img/} }
\DeclareGraphicsExtensions{.png, .jpg}

\title{Ensemble methods}
\author{Kristian Wichmann}

\begin{document}
\maketitle

\textit{Ensemble learning} in machine learning is broadly speaking the practice of making a collection - an \textit{ensemble} - of models, and combine them into a single model with more desired properties.

\section{Bagging and boosting}
There are two broad categories of such meta-algorithms:

\subsection{Bagging}
\textit{Bagging} is short for \textit{bootstrap aggregation}. This is because the ensembles are made through bootstrapping, i.e. random resampling from the training set. Properties of these meta-algorithms:

\begin{itemize}
\item Ensembles are build independently in \textit{parallel}.
\item Tends to reduce variance.
\end{itemize}

\subsection{Boosting}
Properties of these meta-algorithms:
\begin{itemize}
\item Ensembles are build \textit{sequentially}, each building on the ones before.
\item Tends to reduce bias.
\end{itemize}

\section{Simple, unweighted boosting}
As noted above, the general idea behind boosting is to combine an ensemble of weak learners into one strong learner. Here, the term \textit{weak learner} means one that is slightly better than random guessing.

\subsection{Wisdom of the crowd}
The most basic type of boosting is known from the quiz show "Who wants to be a Millionaire?". One of the lifelines is asking the audience. Here, a simple majority vote determines what is usually the best answer. This phenomenon is also known as the \textit{wisdom of the crowd}.

The procedure above describes a classification problem. For regression type problems, the mean of the individual predictions would be used instead of majority vote.

\subsection{Example: Binary classification with three learners}
As a simple example consider three binary classifiers $h_1, h_2, h_3$ on a training set $X$. The two classes corresponds to values of $\pm 1$. The true labels are denoted $f(x)$. Then the simple boosting classifier as described above can be written like:
\begin{equation}
H(x)=\textrm{sgn}\left[h_1(x)+h_2(x)+h_3(x)\right]
\label{simple_three_boost}
\end{equation} 

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{three_unweighted}
\caption{Regions of error for the binary classification with three learners.}
\label{fig:three_unweighted}
\end{figure}

The situation is visualized in figure \ref{fig:three_unweighted}. Each of the three initial classifiers has a region in which its prediction is wrong. These are shown as the regions 1, 2, and 3 respectively. The boosted classifier is only wrong when two or all of the three initial classifiers are wrong. In other words, the error region for $H$ consists of the union of the four regions in orange, green, purple, and white.

Now, initially this looks like an improvement, but in fact in needs not be! Imagine that there's one data point in each of the four regions mentioned above, and none in the yellow, red and blue ones. Then each of $h_1, h_2$, and $h_3$ misclassify three points, while $H$ actually misclassifies four!

\section{AdaBoost}
As the example above shows, we need to be more clever to ensure a good boosting strategy. \textit{AdaBoost}, which is short for \textit{adaptive boosting} is one such widely used algorithm.

\subsection{Weighted binary classification}
Consider equation \ref{simple_three_boost}, but for $T$ learner instead of three. We can generalize this by including \textit{weights} for each classifier:
\begin{equation}
H(x)=\textrm{sgn}\left[\sum_{t=1}^T \alpha_t h_t(x)\right]
\label{boosted_classifier}
\end{equation}
This introduces more flexibility - more \textit{capacity} - to our boosted model. The question now of course is both how to create the classifiers $h_t$ and how to pick the weights $\alpha_t$ appropriately.

\subsection{The base algorithm}
To build our weak learners, we must use some \textit{base algorithm}, which we will denote $\mathcal{L}$ for short. The only requirement is, that for a given probability distribution $D$ on the training set $X$, we can build a classifier:
\begin{equation}
\mathcal{L}[X,D]
\end{equation}

\subsection{Distributions}
We describe the distributions $D$ through a series of weights for each sample in the training set of size $N$. These should sum to one:
\begin{equation}
\sum_{i=1}^N w_i=1
\end{equation}
The starting point - at what we will call time step 1 - will be a distribution where the weights are evenly distributed:
\begin{equation}
w_i^{(1)}=\frac{1}{N}
\label{time_step_1}
\end{equation}
We will denote this $D^{(1)}$ for short, and generally $D^{(t)}$ for the $t$'th time step.

\subsection{The algorithm}
We now build the $T$ classifiers as follows:
\begin{itemize}
\item Start at time step $t=1$, i.e. with a distribution $D^{(1)}$ as described through equation \ref{time_step_1}.
\item Repeat:
\begin{itemize}
\item Build the classifier $h_t=\mathcal{L}[X,D^{(t)}]$.
\item Calculate the error rate for $h_t$:
\begin{equation}
\epsilon_t=\sum_{h_t(x_i)\neq f(x_i)}w_i
\end{equation}
\item If $h_t$ is not a weak classifier, i.e. if $\epsilon_t>0.5$, then break.
\item Set the weight for the classifier to:
\begin{equation}
\alpha_t=\frac{1}{2}\ln\left(\frac{1-\epsilon_t}{\epsilon_t}\right)
\end{equation}
\item Set the weights for the distribution $D^{(t+1)}$ of the next time step:
\begin{equation}
w^{(t+1)}_i=\frac{w^{(t)}_i}{Z_t}\exp\left[-\alpha_t h_t(x_i)f(x_i)\right]
\end{equation}
Here $Z_t=\sum_{i=1}^N w^{(t)}_i\exp\left[-\alpha_t h_t(x_i)f(x_i)\right]$ is a normalization constant.
\item Go to the next time step, unless $t=T$.
\end{itemize}
\item Construct the boosted classifier as:
\begin{equation}
H(x)=\textrm{sgn}\left[\sum_{t=1}^T \alpha_t h_t(x)\right]
\end{equation}
\end{itemize}

\subsection{Mathematical justification}
AdaBoost is a \textit{greedy} algorithm, in that it chooses the best available option in each step: Each time we add another classifier to the sum in equation \ref{boosted_classifier}, we wish to do in a way that minimizes a reasonable \textit{loss function}.

Let's start by naming the partial sum combinations from equation \ref{boosted_classifier}:
\begin{equation}
C_m(x)=\sum_{t=1}^m \alpha_t h_t(x)
\end{equation}
Now assuming we have trained the $m-1$ classifiers and obtained appropriate weights, we're faced with finding $h_m$ and $\alpha_m$. The classifier we're looking to optimize is the sign of:
\begin{equation}
h=C_{m-1}+\alpha_m h_m
\label{cm_definition}
\end{equation}

Consider the following \textit{exponential loss function}:
\begin{equation}
\ell(h|D)=\mathbb{E}_D\left[\exp(-h(x)f(x))\right]
\end{equation}
Here $h$ is the classifier (without the sign function), and $D$ a distribution described by a set of weights $w_i$. When a data point is correctly classified, we get a negative inside the exponential. Similarly, when a data point is incorrectly classified, we get a positive. So it makes sense to minimize this loss function.

We can rewrite the exponential loss function through the weights:
\begin{align}
\ell(h|D)=&\sum_{i=1}^N w_i\exp[-h(x_i)f(x_i)]=\\
&\sum_{i=1}^N w_i\exp[-(C_{m-1}(x_i)+\alpha_m h_m(x_i))f(x_i)]=\\
&\sum_{i=1}^N\underbrace{w_i\exp[-C_{m-1}(x_i)f(x_i)]}_{w'_i}\exp[-\alpha_m h_m(x_i)f(x_i)]=\\
&\sum_{i=1}^N w'_i\exp[-\alpha_m h_m(x_i)f(x_i)]
\end{align}
Here, modified weights $w'_i$ have been introduced.

Now we can minimize $\ell$ with respect to $\alpha_m$ by differentiating:
\begin{equation}
\frac{\partial\ell}{\partial\alpha_m}=\sum_{i=1}^N w'_i\exp[-\alpha_m h_m(x_i)f(x_i)]h_m(x_i)f(x_i)
\end{equation}
We can now split the sum into two parts, according to whether $h_m$ gets the classification right or wrong. When it is right, $h_m(x_i)f(x_i)=1$, and when it is wrong $h_m(x_i)f(x_i)=-1$. So:
\begin{equation}
\frac{\partial\ell}{\partial\alpha_m}=\sum_{h_m(x_i)=f(x_i)}w'_i e^{-\alpha_m}-\sum_{h_m(x_i)\neq f(x_i)}w'_i e^{\alpha_m}
\end{equation}



\end{document}